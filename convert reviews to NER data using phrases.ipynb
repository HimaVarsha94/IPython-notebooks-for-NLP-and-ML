{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from itertools import chain\n",
    "import pycrfsuite\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import sklearn\n",
    "from nltk import word_tokenize\n",
    "import pdb\n",
    "from collections import OrderedDict\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename =\"Hotels_test_data.xlsx\"\n",
    "df = pd.read_excel(filename,\"TrainingData\")\n",
    "classes = (pd.read_excel(filename, \"Classes\"))['classes'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_reviews(sent):\n",
    "    try:\n",
    "        splitted_review = sent['content_and_phrases'].split(\"|\")\n",
    "        review = splitted_review[0]\n",
    "        phrases = splitted_review[1:]\n",
    "        themes = sent['gl_themes'].split(\"|\")\n",
    "        if len(themes)!=len(phrases):\n",
    "            return 0\n",
    "        else:\n",
    "            return review, phrases, themes\n",
    "    except:\n",
    "        pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_ = (df[['content_and_phrases','gl_themes']].apply(split_reviews,axis=1)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(input_)):\n",
    "    while True:\n",
    "        try:\n",
    "            input_[i][1].remove(\"\")\n",
    "            input_[i][2].remove(\"\")\n",
    "        except ValueError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contains(small, big):\n",
    "    for i in xrange(len(big)-len(small)+1):\n",
    "        for j in xrange(len(small)):\n",
    "            if big[i+j] != small[j]:\n",
    "                break\n",
    "        else:\n",
    "            return i, i+len(small)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "count = 0\n",
    "# contains(word_tokenize(input_[0][1][2]),word_tokenize(input_[0][0]))\n",
    "def filter_eos(a):\n",
    "    a = filter(lambda a: a != \",\" and a != \".\" and a != \"?\" and a != \"!\", a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BIOtagging_sentence(row_, count):\n",
    "    review = row_[0]\n",
    "    themes = row_[2]\n",
    "    phrases = row_[1]\n",
    "    tokenized_review = filter_eos(word_tokenize(review))\n",
    "    pos_tags = nltk.pos_tag(tokenized_review)\n",
    "    BIO_tags = []\n",
    "    for i in xrange(len(tokenized_review)):\n",
    "        BIO_tags.append((tokenized_review[i],pos_tags[i][1],\"O\"))\n",
    "    for j in xrange(len(phrases)):\n",
    "        phrase_tokens = filter_eos(word_tokenize(phrases[j]))\n",
    "        try:\n",
    "            class_theme = classes.index(themes[j])\n",
    "        except:\n",
    "            continue\n",
    "        if contains(phrase_tokens, tokenized_review) != False:\n",
    "            start, end = contains(phrase_tokens, tokenized_review)\n",
    "            BIO_tags[start] = (tokenized_review[start],pos_tags[start][1],\"B-\"+str(class_theme))\n",
    "            for k in xrange(start+1, end):\n",
    "                BIO_tags[k] = (tokenized_review[k],pos_tags[k][1],\"I-\"+str(class_theme))\n",
    "        else:\n",
    "            count = count + 1\n",
    "    return BIO_tags, count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tags = []\n",
    "count = 0\n",
    "for i in xrange(len(input_)):\n",
    "    tags_, count = (BIOtagging_sentence(input_[i], count))\n",
    "#     count = count + count_\n",
    "    all_tags.append(tags_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trained NER Models/test_BIO_Hotels.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(all_tags, \"Trained NER Models/test_BIO_Hotels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
