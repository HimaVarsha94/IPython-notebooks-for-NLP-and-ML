{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from itertools import chain\n",
    "import pycrfsuite\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename =\"Hotels_train_phrase_below_reviews_data.xlsx\"\n",
    "df = pd.read_excel(filename,\"phrases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theme</th>\n",
       "      <th>index</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Phrases</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game drive experience</td>\n",
       "      <td>10</td>\n",
       "      <td>positive</td>\n",
       "      <td>Game Drives are the best</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quality of food</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>the food was delicious</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Safari experience</td>\n",
       "      <td>17</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Africa in the past 35 years and never actually...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Safari experience</td>\n",
       "      <td>17</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Africa in the past 35 years and never actually...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quality of food</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>peaceful lunch on the lawn,</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   theme  index sentiment  \\\n",
       "0  Game drive experience     10  positive   \n",
       "1        Quality of food      1  positive   \n",
       "2      Safari experience     17   Neutral   \n",
       "3      Safari experience     17   Neutral   \n",
       "4        Quality of food      1  positive   \n",
       "\n",
       "                                             Phrases  Unnamed: 4  \n",
       "0                           Game Drives are the best           5  \n",
       "1                             the food was delicious           4  \n",
       "2  Africa in the past 35 years and never actually...          29  \n",
       "3  Africa in the past 35 years and never actually...          29  \n",
       "4                        peaceful lunch on the lawn,           5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "def extract_pos(sent):\n",
    "    try:\n",
    "        tokens = word_tokenize(sent)\n",
    "        return nltk.pos_tag(tokens)\n",
    "    except:\n",
    "        import pdb\n",
    "        pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "def extract_BIO2_pos(sent):\n",
    "    try:\n",
    "        tokens = word_tokenize(sent['Phrases'])\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        counter = 1\n",
    "        BIO2 = []\n",
    "        for token in tokens:\n",
    "            pos = (nltk.pos_tag([token]))[0][1]\n",
    "            if counter == 1:\n",
    "                theme = \"B-\"+str(sent['index'])\n",
    "                BIO2.append((token, pos, theme))\n",
    "                counter = 0\n",
    "            else:\n",
    "                pos = (nltk.pos_tag([token]))[0][1]\n",
    "                theme = \"I-\"+str(sent['index'])\n",
    "                BIO2.append((token, pos, theme))\n",
    "#                 BIO2token, pos, theme\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    return BIO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_tags = df[['Phrases','index']].apply(extract_BIO2_pos,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 365 ms, sys: 36.6 ms, total: 401 ms\n",
      "Wall time: 406 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pos_tags = pos_tags.tolist()\n",
    "train_sents = pos_tags[:4960]\n",
    "test_sents = pos_tags[4961:]\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.train('hotels.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x116171590>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('hotels.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Predicted:', 'B-3 I-3 I-3 I-3 I-3 I-3')\n",
      "('Correct:  ', 'B-3 I-3 I-3 I-3 I-3 I-3')\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_sents[0]\n",
    "# print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        B-0       0.57      0.77      0.66        53\n",
      "        I-0       0.62      0.77      0.69       430\n",
      "        B-1       0.46      1.00      0.63        31\n",
      "        I-1       0.40      1.00      0.57       136\n",
      "       B-10       0.61      0.69      0.65        36\n",
      "       I-10       0.62      0.69      0.65       318\n",
      "       B-11       0.52      0.44      0.48        55\n",
      "       I-11       0.49      0.36      0.42       350\n",
      "       B-12       0.82      0.74      0.78        50\n",
      "       I-12       0.74      0.68      0.71       196\n",
      "       B-13       0.81      0.71      0.75        41\n",
      "       I-13       0.83      0.71      0.77       417\n",
      "       B-14       0.59      0.59      0.59        22\n",
      "       I-14       0.64      0.63      0.63       187\n",
      "       B-15       0.93      0.62      0.74        42\n",
      "       I-15       0.90      0.66      0.77       280\n",
      "       B-16       0.88      0.25      0.39        28\n",
      "       I-16       0.86      0.23      0.36       209\n",
      "       B-17       0.83      0.70      0.76        27\n",
      "       I-17       0.76      0.60      0.67       189\n",
      "       B-18       0.20      1.00      0.33         1\n",
      "       I-18       0.36      1.00      0.53        10\n",
      "       B-19       1.00      0.31      0.47        29\n",
      "       I-19       0.77      0.27      0.40       135\n",
      "        B-2       0.53      0.85      0.65        86\n",
      "        I-2       0.50      0.89      0.64       875\n",
      "       B-20       0.75      0.40      0.52        15\n",
      "       I-20       0.80      0.54      0.64        84\n",
      "       B-21       1.00      0.59      0.74        22\n",
      "       I-21       0.97      0.73      0.83       128\n",
      "       B-22       0.00      0.00      0.00        20\n",
      "       I-22       0.81      0.21      0.34       118\n",
      "       B-23       0.00      0.00      0.00        10\n",
      "       I-23       0.86      0.36      0.51        33\n",
      "       B-24       0.00      0.00      0.00         8\n",
      "       I-24       0.00      0.00      0.00       123\n",
      "       B-25       0.00      0.00      0.00         7\n",
      "       I-25       0.82      0.14      0.24        64\n",
      "       B-26       0.00      0.00      0.00         4\n",
      "       I-26       0.00      0.00      0.00        47\n",
      "       B-27       0.00      0.00      0.00        18\n",
      "       I-27       0.60      0.13      0.22       137\n",
      "       B-28       0.00      0.00      0.00        11\n",
      "       I-28       0.00      0.00      0.00       106\n",
      "       B-29       0.00      0.00      0.00        12\n",
      "       I-29       0.00      0.00      0.00       173\n",
      "        B-3       0.40      0.71      0.51       116\n",
      "        I-3       0.39      0.69      0.49       816\n",
      "       B-30       0.00      0.00      0.00         4\n",
      "       I-30       0.00      0.00      0.00        34\n",
      "       B-31       0.00      0.00      0.00        11\n",
      "       I-31       0.00      0.00      0.00       103\n",
      "       B-32       0.00      0.00      0.00         7\n",
      "       I-32       0.00      0.00      0.00        32\n",
      "       B-33       0.00      0.00      0.00         3\n",
      "       I-33       0.00      0.00      0.00        28\n",
      "       B-34       0.00      0.00      0.00         4\n",
      "       I-34       0.00      0.00      0.00        15\n",
      "       B-35       0.00      0.00      0.00         3\n",
      "       I-35       0.00      0.00      0.00        28\n",
      "       B-36       0.00      0.00      0.00         3\n",
      "       I-36       0.00      0.00      0.00        25\n",
      "       B-37       0.00      0.00      0.00         3\n",
      "       I-37       0.00      0.00      0.00         6\n",
      "        B-4       0.81      0.74      0.77        23\n",
      "        I-4       0.78      0.65      0.71       251\n",
      "        B-5       0.52      0.63      0.57        97\n",
      "        I-5       0.51      0.72      0.60       802\n",
      "        B-6       0.92      0.79      0.85        75\n",
      "        I-6       0.88      0.59      0.71       273\n",
      "        B-7       0.85      0.63      0.72        54\n",
      "        I-7       0.79      0.50      0.61       312\n",
      "        B-8       0.88      0.66      0.75        65\n",
      "        I-8       0.84      0.65      0.73       371\n",
      "        B-9       0.85      0.85      0.85        75\n",
      "        I-9       0.87      0.78      0.82       500\n",
      "\n",
      "avg / total       0.61      0.60      0.57      9512\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/himavarsha/Envs/sklearn/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-3', 'I-3', 'I-3', 'I-3', 'I-3', 'I-3']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeBIO_and_merge(y_values):\n",
    "    all_tags = []\n",
    "    for values_ in y_values:\n",
    "        set_values = set()\n",
    "        for value in values_:\n",
    "            value = int(value[2:])\n",
    "            set_values.add(value)\n",
    "        all_tags.append(list(set_values))\n",
    "        \n",
    "    return all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = removeBIO_and_merge(y_pred)\n",
    "y_test = removeBIO_and_merge(y_test)\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_test_lb = mlb.fit_transform((y_test))\n",
    "y_pred_lb = mlb.transform((y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.77      0.66        53\n",
      "          1       0.46      1.00      0.63        31\n",
      "          2       0.53      0.85      0.65        86\n",
      "          3       0.40      0.71      0.51       116\n",
      "          4       0.81      0.74      0.77        23\n",
      "          5       0.52      0.63      0.57        97\n",
      "          6       0.92      0.79      0.85        75\n",
      "          7       0.85      0.63      0.72        54\n",
      "          8       0.88      0.66      0.75        65\n",
      "          9       0.87      0.87      0.87        75\n",
      "         10       0.62      0.72      0.67        36\n",
      "         11       0.51      0.44      0.47        55\n",
      "         12       0.83      0.78      0.80        50\n",
      "         13       0.81      0.71      0.75        41\n",
      "         14       0.59      0.59      0.59        22\n",
      "         15       0.90      0.64      0.75        42\n",
      "         16       0.78      0.25      0.38        28\n",
      "         17       0.83      0.70      0.76        27\n",
      "         18       0.20      1.00      0.33         1\n",
      "         19       0.95      0.66      0.78        29\n",
      "         20       0.82      0.60      0.69        15\n",
      "         21       1.00      0.77      0.87        22\n",
      "         22       1.00      0.30      0.46        20\n",
      "         23       1.00      0.50      0.67        10\n",
      "         24       0.00      0.00      0.00         8\n",
      "         25       1.00      0.29      0.44         7\n",
      "         26       0.00      0.00      0.00         4\n",
      "         27       0.75      0.17      0.27        18\n",
      "         28       0.00      0.00      0.00        11\n",
      "         29       0.00      0.00      0.00        12\n",
      "         30       0.00      0.00      0.00         4\n",
      "         31       0.00      0.00      0.00        11\n",
      "         32       0.00      0.00      0.00         7\n",
      "         33       0.00      0.00      0.00         3\n",
      "         34       0.00      0.00      0.00         4\n",
      "         35       0.00      0.00      0.00         3\n",
      "         36       0.00      0.00      0.00         3\n",
      "         37       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.66      0.64      0.63      1171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len(y_pred_lb)\n",
    "print classification_report(y_test_lb,y_pred_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1171"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(chain.from_iterable([[1,2],[3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
